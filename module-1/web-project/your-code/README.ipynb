{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Requirements\n",
    "\n",
    "The technical requirements for this project are as follows:\n",
    "\n",
    "* You must obtain data from an API using Python.\n",
    "* You must scrape and clean HTML from a web page using Python.\n",
    "* The results should be two files - one containing the tabular results of your API request and the other containing the results of your web page scrape.\n",
    "* Your code should be saved in a Jupyter Notebook and your results should be saved in a folder named output.\n",
    "* You should include a README.md file that describes the steps you took and your thought process for obtaining data from the API and web page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Necessary Deliverables\n",
    "\n",
    "The following deliverables should be pushed to your Github repo for this chapter.\n",
    "\n",
    "* **A Jupyter Notebook (.ipynb) file** that contains the code used to work with your API and scrape your web page.\n",
    "* **An output folder** containing the outputs of your API and scraping efforts.\n",
    "* **A ``README.md`` file** containing a detailed explanation of your approach and code for retrieving data from the API and scraping the web page as well as your results, obstacles encountered, and lessons learned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested Ways to Get Started\n",
    "\n",
    "* **Find an API to work with** - a great place to start looking would be [API List](https://apilist.fun/) and [Public APIs](https://github.com/toddmotto/public-apis). If you need authorization for your chosen API, make sure to give yourself enough time for the service to review and accept your application. Have a couple back-up APIs chosen just in case!\n",
    "* **Find a web page to scrape** and determine the content you would like to scrape from it - blogs and news sites are typically good candida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Necessary Deliverables\n",
    "\n",
    "The following deliverables should be pushed to your Github repo for this chapter.\n",
    "\n",
    "* **A Jupyter Notebook (.ipynb) file** that contains the code used to work with your API and scrape your web page.\n",
    "* **An output folder** containing the outputs of your API and scraping efforts.\n",
    "* **A ``README.md`` file** containing a detailed explanation of your approach and code for retrieving data from the API and scraping the web page as well as your results, obstacles encountered, and lessons learned.\n",
    "tes for scraping text content, and [Wikipedia](https://www.wikipedia.org/) is usually a good source for HTML tables (search for \"list of...\").\n",
    "* **Break the project down into different steps** - note the steps covered in the API and web scraping lessons, try to follow them, and make adjustments as you encounter the obstacles that are inevitable due to all APIs and web pages being different.\n",
    "* **Use the tools in your tool kit** - your knowledge of intermediate Python as well as some of the things you've learned in previous chapters. This is a great way to start tying everything you've learned together!\n",
    "* **Work through the lessons in class** & ask questions when you need to! Think about adding relevant code to your project each night, instead of, you know... _procrastinating_.\n",
    "* **Commit early, commit often**, donâ€™t be afraid of doing something incorrectly because you can always roll back to a previous version.\n",
    "* **Consult documentation and resources provided** to better understand the tools you are using and how to accomplish what you want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Useful Resources\n",
    "\n",
    "* [Requests Library Documentation: Quickstart](http://docs.python-requests.org/en/master/user/quickstart/)\n",
    "* [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "* [Stack Overflow Python Requests Questions](https://stackoverflow.com/questions/tagged/python-requests)\n",
    "* [StackOverflow BeautifulSoup Questions](https://stackoverflow.com/questions/tagged/beautifulsoup)\n",
    "\n",
    "## Project Feedback + Evaluation\n",
    "\n",
    "* __Technical Requirements__: Did you deliver a project that met all the technical requirements? Given what the class has covered so far, did you build something that was reasonably complex?\n",
    "\n",
    "* __Creativity__: Did you add a personal spin or creative element into your project submission? Did you incorporate domain knowledge or unique perspective into your analysis.\n",
    "\n",
    "* __Code Quality__: Did you follow code style guidance and best practices covered in class?\n",
    "\n",
    "* __Total__: Your instructors will give you a total score on your project between:\n",
    "\n",
    "    **Score**|**Expectations**\n",
    "    -----|-----\n",
    "    0|Does not meet expectations\n",
    "    1|Meets expectactions, good job!\n",
    "    2|Exceeds expectations, you wonderful creature, you!\n",
    "\n",
    "This will be useful as an overall gauge of whether you met the project goals, but __the more important scores are described in the specs above__, which can help you identify where to focus your efforts for the next project!\n",
    "\n",
    "## Presentation Guideline and Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things you might want to talk about\n",
    "Short presentation of yourself:\n",
    "- Who are you?\n",
    "- A hobby you have.\n",
    "Note: we are getting you ready for final presentation!\n",
    "Elevator pitch:\n",
    "- The API and web page your chose.\n",
    "- Why did you chose that API and web page?\n",
    "- The most important thing you learned.\n",
    "- One technical challenge you faced:\n",
    "- Explain the challenge.\n",
    "- Explain how and what you did to overcome it.\n",
    "Show and explain code snippets in your presentation slides.\n",
    "Git:\n",
    "Display an screenshot of your GitHub graphs to show your commit frequency and how much work you did.\n",
    "API Walkthrough:\n",
    "Walk the audience through the API you chose, the type of data you decided to obtain from it, and how you went about calling the API, obtaining that data, and structuring it.\n",
    "Web Scraping Walkthrough:\n",
    "Walk the audience through the web page you chose, the type of data you decided to obtain from it, and how you went about scraping the page, parsing the HTML, and cleaning the data.\n",
    "One important mistake you made:\n",
    "Did you call the API incorrectly? Did you make some errors while scraping the web page?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

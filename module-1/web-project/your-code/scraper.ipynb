{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETRAS_ROOT_URL = \"https://www.letras.com\"\n",
    "LETRAS_REGGAETON_URL = LETRAS_ROOT_URL + \"/mais-acessadas/reggaeton/\"\n",
    "\n",
    "# OBTENEMOS LA PÁGINA DONDE SALEN TODOS LOS ARTISTAS DE REGGAETON\n",
    "\n",
    "response = requests.get(LETRAS_REGGAETON_URL)\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Achicamos la búsqueda al contenedor\n",
    "artists_container = soup.find(\"ol\", {'class': 'top-list_art'})\n",
    "\n",
    "# Como ya hemos achicado al contenedor, buscamos el patrón que se repite. En este caso las etiquetas \"a\"\n",
    "artists_html = artists_container.find_all(\"a\")\n",
    "\n",
    "# Creamos la lista con las URL de los artistas. Esta lista está compuesta por listas de 2 elementos: URL y nombre del artista.\n",
    "artists_href = [[artist.get('href'), artist.text] for artist in artists_html]\n",
    "\n",
    "# Creamos un dataframe con las columnas artista, título de la canción y la letra.\n",
    "df = pd.DataFrame(columns=['Artist', 'Title', 'Lyrics'])\n",
    "\n",
    "for artist_href in artists_href:\n",
    "    artist_href[0] = LETRAS_ROOT_URL + artist_href[0]\n",
    "\n",
    "    # OBTENEMOS LA PÁGINA DONDE SALEN LOS TÍTULOS DE LAS TOP 20 CANCIONES DEL ARTISTA\n",
    "\n",
    "    art_response = requests.get(artist_href[0])\n",
    "    art_soup = BeautifulSoup(art_response.text, \"html.parser\")\n",
    "\n",
    "    # Achicamos la búsqueda al contenedor\n",
    "    songs_container = art_soup.find(\"ol\", {'class': 'cnt-list cnt-list--num cnt-list--col2'})\n",
    "    \n",
    "    # Como ya hemos achicado al contenedor, buscamos el patrón que se repite. En este caso es la etiqueta \"a\".\n",
    "    songs_html = songs_container.find_all(\"a\")\n",
    "\n",
    "    # Creamos la lista con las URL de las canciones. Esta lista está compuesta por listas de 2 elementos: URL y título de la canción.\n",
    "    songs_href = [[song.get('href'), song.text] for song in songs_html]\n",
    "\n",
    "    # Imprimimos las URL de cada una de las canciones de los artistas.\n",
    "    # pprint(songs_href)\n",
    "\n",
    "    for song_href in songs_href:\n",
    "        song_href[0] = LETRAS_ROOT_URL + song_href[0]\n",
    "        \n",
    "        # OBTENEMOS LA PÁGINA DONDE SALE LA LETRA DE LA CANCIÓN\n",
    "        \n",
    "        song_response = requests.get(song_href[0])\n",
    "        song_soup = BeautifulSoup(song_response.text, \"html.parser\")\n",
    "\n",
    "        # Achicamos la búsqueda al contenedor\n",
    "        paragraphs_container = song_soup.find(\"div\", {'class': 'cnt-letra p402_premium'})\n",
    "\n",
    "        # Como ya hemos achicado al contenedor, buscamos el patrón que se repite. En este caso las etiquetas \"p\".\n",
    "        paragraphs_html = paragraphs_container.find_all(\"p\")\n",
    "        \n",
    "        # Normalmente crearíamos la lista con las letras de las canciones de la siguiente forma.\n",
    "        # lyrics = [paragraph.text.splitlines() for paragraph in paragraphs_html]\n",
    "        # Pero no lo voy a hacer así porque no me permite sacar los versos.\n",
    "        # Voy a sacar las lyrics como paragraphs_html y más adelante le haré un tratamiento con pandas para que\n",
    "        # cada canción sean una lista con tantas strings como versos tenga.\n",
    "        \n",
    "        # Aprovechando el loop, vamos añadiendo al dataframe cada letra (html), con su título y artista correspondiente.\n",
    "        # Incluyo \"ignore_index=True\" para que los index se vayan añadiendo de forma incremental.\n",
    "        df = df.append({'Artist': artist_href[1], 'Title': song_href[1], 'Lyrics': paragraphs_html} , ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html_tags(l):\n",
    "    \"\"\"\n",
    "    Receive a list, remove the 'p' and 'br' html tags and return a clean list.\n",
    "    List can contain any type (lists, strings, bs4.elements...)\n",
    "    \"\"\"\n",
    "    clean_list = []\n",
    "    for e in l:\n",
    "        e = str(e)\n",
    "        e = e.replace(\"<p>\", \"\")\n",
    "        e = e.replace(\"</p>\", \"\")\n",
    "        e = e.replace(\"<br>\", \"<br/>\")\n",
    "        e = e.replace(\"</br>\", \"<br/>\")\n",
    "        e = e.split(\"<br/>\")\n",
    "        clean_list.append(e)\n",
    "    return clean_list\n",
    "\n",
    "\n",
    "def flatten_list(l):\n",
    "    \"\"\"\n",
    "    Receive a list of lists and return a list with just one element.\n",
    "    \"\"\"\n",
    "    return sum(l, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplico las dos funciones que convierten las lyrics de bs4 elements a lista de strings, donde cada string es un verso.\n",
    "df['Lyrics'] = df['Lyrics'].apply(clean_html_tags)\n",
    "df['Lyrics'] = df['Lyrics'].apply(flatten_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(dataframe):\n",
    "    dataframe.to_csv(\"Reggaeton_lyrics.csv\")\n",
    "load(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

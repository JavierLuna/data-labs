{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re, string, unicodedata\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "#import contractions\n",
    "#import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MADRID_URL = \"https://www.madridiario.es/sucesos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\") #parser para que no se queje\n",
    "    return soup\n",
    "\n",
    "soup = get_soup(MADRID_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Un motorista, herido grave mientras circulaba por el Circuito del Jarama',\n",
      " 'Una nave industrial, arrasada por un incendio en Alcalá de Henares',\n",
      " 'Un paracaidista cae a un tejado en el encuentro de veteranos de la Base '\n",
      " 'Príncipe de Paracuellos',\n",
      " 'Un accidente entre un coche y una moto se salda con un herido grave en Parla',\n",
      " 'Un hombre sufre varios traumatismos graves al caer con su bicicleta en la '\n",
      " 'carretera',\n",
      " 'Desarticulado un grupo criminal que se dedicaba al robo de coches para su '\n",
      " 'posterior venta']\n"
     ]
    }
   ],
   "source": [
    "def get_headers(soup):\n",
    "    news = []\n",
    "    headers_container = soup.find_all(\"h2\", {'class': 'titulo'})\n",
    "    for header in headers_container:\n",
    "        news.append(header.text)\n",
    "    return news\n",
    "\n",
    "news_raw = get_headers(soup) #return dataframe\n",
    "pprint(news_raw[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['un motorista, herido grave mientras circulaba por el circuito del jarama',\n",
      " 'una nave industrial, arrasada por un incendio en alcalá de henares',\n",
      " 'un paracaidista cae a un tejado en el encuentro de veteranos de la base '\n",
      " 'príncipe de paracuellos',\n",
      " 'un accidente entre un coche y una moto se salda con un herido grave en parla',\n",
      " 'un hombre sufre varios traumatismos graves al caer con su bicicleta en la '\n",
      " 'carretera',\n",
      " 'desarticulado un grupo criminal que se dedicaba al robo de coches para su '\n",
      " 'posterior venta']\n"
     ]
    }
   ],
   "source": [
    "# Get rid of lower-cases\n",
    "def tolower (work_list):\n",
    "    return [row.lower() for row in work_list]\n",
    "    \n",
    "news_raw = tolower(news_raw)\n",
    "pprint(news_raw[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['un motorista, herido grave mientras circulaba por el circuito del jarama',\n",
      " 'una nave industrial, arrasada por un incendio en alcala de henares',\n",
      " 'un paracaidista cae a un tejado en el encuentro de veteranos de la base '\n",
      " 'principe de paracuellos',\n",
      " 'un accidente entre un coche y una moto se salda con un herido grave en parla',\n",
      " 'un hombre sufre varios traumatismos graves al caer con su bicicleta en la '\n",
      " 'carretera',\n",
      " 'desarticulado un grupo criminal que se dedicaba al robo de coches para su '\n",
      " 'posterior venta']\n"
     ]
    }
   ],
   "source": [
    "# Get rid of accents\n",
    "def clean_accent(work_list):\n",
    "    return [row.replace('á','a').replace('é','e').replace('í','i').replace('ó','o').replace('ú','u') for row in work_list]\n",
    "\n",
    "news_raw2 = clean_accent(news_raw)\n",
    "pprint(news_raw2[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['un motorista herido grave mientras circulaba por el circuito del jarama',\n",
      " 'una nave industrial arrasada por un incendio en alcala de henares',\n",
      " 'un paracaidista cae a un tejado en el encuentro de veteranos de la base '\n",
      " 'principe de paracuellos',\n",
      " 'un accidente entre un coche y una moto se salda con un herido grave en parla',\n",
      " 'un hombre sufre varios traumatismos graves al caer con su bicicleta en la '\n",
      " 'carretera',\n",
      " 'desarticulado un grupo criminal que se dedicaba al robo de coches para su '\n",
      " 'posterior venta']\n"
     ]
    }
   ],
   "source": [
    "#Get rid of commas\n",
    "def clean_commas(work_list):\n",
    "    return [row.replace(',','') for row in work_list]\n",
    "\n",
    "dfnews_raw3 = clean_commas(news_raw2)\n",
    "pprint(dfnews_raw3[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['un', 'motorista', 'herido', 'grave', 'mientras', 'circulaba', 'por', 'el', 'circuito', 'del', 'jarama'], ['una', 'nave', 'industrial', 'arrasada', 'por', 'un', 'incendio', 'en', 'alcala', 'de', 'henares']]\n"
     ]
    }
   ],
   "source": [
    "# Get each word / Tokenizar\n",
    "def token(work_list):\n",
    "    return [nltk.word_tokenize(row) for row in work_list]\n",
    "\n",
    "token_news = token(dfnews_raw3)\n",
    "print(token_news[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estamos', 'serías', 'tendría', 'vuestra', 'hubieron', 'habrían', 'sea', 'vosostras', 'hayáis', 'sentida', 'está', 'fueran', 'míos', 'sobre', 'estuviesen', 'sois', 'y', 'hubiesen', 'tengáis', 'del', 'estada', 'habríamos', 'porque', 'hube', 'tuyos', 'es', 'tuya', 'estaréis', 'están', 'vosostros', 'hubiera', 'fuimos', 'hubieran', 'ese', 'éramos', 'ante', 'por', 'esta', 'tendré', 'tendríais', 'habíais', 'estuvieran', 'hubieras', 'nosotras', 'sentido', 'estáis', 'tendrán', 'habíamos', 'serás', 'esa', 'tened', 'mías', 'desde', 'estarán', 'estuviéramos', 'erais', 'hubiéramos', 'en', 'os', 'hubieseis', 'estuvisteis', 'tenía', 'tenemos', 'vuestro', 'ni', 'tus', 'tenían', 'hubo', 'hubieses', 'tuviste', 'estado', 'sean', 'tuviesen', 'contra', 'habremos', 'tenga', 'e', 'algunas', 'estaremos', 'hayas', 'habida', 'sentid', 'hubiste', 'unos', 'teníais', 'estar', 'esté', 'quienes', 'todo', 'tuvo', 'lo', 'estaríais', 'me', 'tendrías', 'que', 'otras', 'tendréis', 'estuvieseis', 'le', 'estarías', 'estuviera', 'estuviese', 'estuvieses', 'fuesen', 'tuvierais', 'más', 'las', 'nada', 'yo', 'sería', 'habrías', 'el', 'otra', 'entre', 'fueseis', 'se', 'estad', 'te', 'sentidos', 'estuvo', 'los', 'a', 'estén', 'estoy', 'fueron', 'seríais', 'quien', 'ti', 'estés', 'seas', 'habré', 'este', 'tenéis', 'cual', 'estadas', 'fui', 'hayan', 'muy', 'algo', 'fuera', 'sí', 'ya', 'habréis', 'nuestro', 'fueras', 'estuvieron', 'sintiendo', 'tuviésemos', 'estaban', 'estarían', 'estuviste', 'sin', 'vuestros', 'fuésemos', 'muchos', 'habías', 'hay', 'tuvieron', 'para', 'estaríamos', 'he', 'estabais', 'ella', 'cuando', 'serán', 'nos', 'tengan', 'habido', 'suya', 'has', 'había', 'tuyas', 'otros', 'tengas', 'tendrá', 'tuyo', 'tenidas', 'siente', 'estuviésemos', 'hubimos', 'tienes', 'un', 'donde', 'una', 'otro', 'eran', 'todos', 'estábamos', 'habríais', 'tú', 'uno', 'habrán', 'tuviese', 'estados', 'tendrás', 'seré', 'como', 'han', 'de', 'nuestras', 'serían', 'tuvisteis', 'fuiste', 'era', 'haya', 'suyas', 'tiene', 'tengamos', 'estaré', 'nosotros', 'hasta', 'tu', 'algunos', 'estemos', 'estuvieras', 'durante', 'fueses', 'tengo', 'tenías', 'ellos', 'habidas', 'ellas', 'somos', 'seremos', 'su', 'sus', 'tuviera', 'o', 'no', 'estuvimos', 'qué', 'tendríamos', 'poco', 'eras', 'tanto', 'será', 'habrás', 'fuisteis', 'teniendo', 'estás', 'soy', 'tendremos', 'seamos', 'estuvierais', 'al', 'vuestras', 'la', 'estará', 'mía', 'nuestra', 'esas', 'habían', 'tenidos', 'les', 'antes', 'hubiese', 'fuerais', 'tenida', 'él', 'tienen', 'estuve', 'habrá', 'tendrían', 'tuvimos', 'estos', 'habiendo', 'tuviéramos', 'mi', 'tenido', 'estando', 'hubierais', 'suyo', 'mío', 'habría', 'son', 'tuvieras', 'esos', 'habidos', 'fuéramos', 'habéis', 'tuvieses', 'mis', 'estéis', 'estaba', 'seáis', 'ha', 'mí', 'esto', 'eres', 'estarás', 'tuvieseis', 'hemos', 'suyos', 'hubiésemos', 'fuese', 'mucho', 'tuve', 'estabas', 'hayamos', 'pero', 'teníamos', 'nuestros', 'seríamos', 'fue', 'tuvieran', 'con', 'eso', 'hubisteis', 'estas', 'estaría', 'sentidas', 'seréis', 'también'}\n"
     ]
    }
   ],
   "source": [
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['motorista',\n",
      "  'herido',\n",
      "  'grave',\n",
      "  'mientras',\n",
      "  'circulaba',\n",
      "  'circuito',\n",
      "  'jarama'],\n",
      " ['nave', 'industrial', 'arrasada', 'incendio', 'alcala', 'henares'],\n",
      " ['paracaidista',\n",
      "  'cae',\n",
      "  'tejado',\n",
      "  'encuentro',\n",
      "  'veteranos',\n",
      "  'base',\n",
      "  'principe',\n",
      "  'paracuellos'],\n",
      " ['accidente', 'coche', 'moto', 'salda', 'herido', 'grave', 'parla'],\n",
      " ['hombre',\n",
      "  'sufre',\n",
      "  'varios',\n",
      "  'traumatismos',\n",
      "  'graves',\n",
      "  'caer',\n",
      "  'bicicleta',\n",
      "  'carretera'],\n",
      " ['desarticulado',\n",
      "  'grupo',\n",
      "  'criminal',\n",
      "  'dedicaba',\n",
      "  'robo',\n",
      "  'coches',\n",
      "  'posterior',\n",
      "  'venta'],\n",
      " ['herido', 'grave', 'hombre', 'invidente', 'sordomudo', 'atropellado', 'moto'],\n",
      " ['sentencia',\n",
      "  'supremo',\n",
      "  \"'la\",\n",
      "  'manada',\n",
      "  \"'\",\n",
      "  'reaviva',\n",
      "  'debate',\n",
      "  'reforma',\n",
      "  'codigo',\n",
      "  'penal'],\n",
      " ['localizado', 'argentino', '72', 'años', 'desaparecido', 'barajas'],\n",
      " ['mas',\n",
      "  '130',\n",
      "  'organizaciones',\n",
      "  'feministas',\n",
      "  'volveran',\n",
      "  'entonar',\n",
      "  \"'yo\",\n",
      "  'si',\n",
      "  'creo',\n",
      "  \"'\"],\n",
      " ['fiscal', 'defiende', 'manada', 'cometio', 'violacion', 'continuada'],\n",
      " ['inhabilitada', 'pediatra', 'vinculaba', 'vacunaciones', 'autismo'],\n",
      " ['supremo', 'escucha', 'recursos', 'sentencia', 'manada'],\n",
      " ['chico', '16', 'años', 'acuchilla', 'hermano', 'amigo', 'san', 'blas'],\n",
      " ['pp', 'cesa', 'director', 'general', 'policia', 'tener', 'sustituto'],\n",
      " ['condenado',\n",
      "  'cuatro',\n",
      "  'años',\n",
      "  'asesino',\n",
      "  'olga',\n",
      "  'sangrador',\n",
      "  'abusos',\n",
      "  'menor',\n",
      "  'madrid'],\n",
      " ['detenidos',\n",
      "  '15',\n",
      "  'estafadores',\n",
      "  'hacian',\n",
      "  'pasar',\n",
      "  'tecnicos',\n",
      "  'gas',\n",
      "  'electricidad'],\n",
      " ['herido', 'grave', 'conductor', 'tras', 'chocarse', 'bus'],\n",
      " ['encontrado', 'cuerpo', 'signos', 'violencia', 'tras', 'incendio'],\n",
      " ['auxiliar', 'acusada', 'asesinato', ':', '``', 'quitaria', 'vida', \"''\"]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def clean_stopwords(list_tokens, stp_words):\n",
    "    [row.remove(item) for row in list_tokens for item in row if item in stp_words]\n",
    "    return list_tokens\n",
    "    \n",
    "cleaned_data = clean_stopwords(token_news, stopWords)\n",
    "pprint(cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

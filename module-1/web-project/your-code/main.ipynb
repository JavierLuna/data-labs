{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re, string, unicodedata\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "\n",
    "#import contractions\n",
    "#import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MADRID_URL = \"https://www.madridiario.es/sucesos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\") #parser para que no se queje\n",
    "    return soup\n",
    "\n",
    "soup = get_soup(MADRID_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Un paracaidista cae a un tejado en el encuentr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un accidente entre un coche y una moto se sald...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Un hombre sufre varios traumatismos graves al ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desarticulado un grupo criminal que se dedicab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Herido muy grave un hombre invidente y sordomu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La sentencia del Supremo a 'La Manada' reaviva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Localizado el argentino de 72 años desaparecid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headers\n",
       "0  Un paracaidista cae a un tejado en el encuentr...\n",
       "1  Un accidente entre un coche y una moto se sald...\n",
       "2  Un hombre sufre varios traumatismos graves al ...\n",
       "3  Desarticulado un grupo criminal que se dedicab...\n",
       "4  Herido muy grave un hombre invidente y sordomu...\n",
       "5  La sentencia del Supremo a 'La Manada' reaviva...\n",
       "6  Localizado el argentino de 72 años desaparecid..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_headers(soup):\n",
    "    news = []\n",
    "    headers_container = soup.find_all(\"h2\", {'class': 'titulo'})\n",
    "    for header in headers_container:\n",
    "        news.append(header.text)\n",
    "        \n",
    "    #print(news[:7])    \n",
    "    return pd.DataFrame(data=news, columns=['Headers'])\n",
    "\n",
    "dfnews_raw = get_headers(soup) #return dataframe\n",
    "#print(type(dfnews_raw))\n",
    "\n",
    "dfnews_raw.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Un paracaidista cae a un tejado en el encuentr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un accidente entre un coche y una moto se sald...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Un hombre sufre varios traumatismos graves al ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desarticulado un grupo criminal que se dedicab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Herido muy grave un hombre invidente y sordomu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La sentencia del Supremo a 'La Manada' reaviva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Localizado el argentino de 72 años desaparecid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headers\n",
       "0  Un paracaidista cae a un tejado en el encuentr...\n",
       "1  Un accidente entre un coche y una moto se sald...\n",
       "2  Un hombre sufre varios traumatismos graves al ...\n",
       "3  Desarticulado un grupo criminal que se dedicab...\n",
       "4  Herido muy grave un hombre invidente y sordomu...\n",
       "5  La sentencia del Supremo a 'La Manada' reaviva...\n",
       "6  Localizado el argentino de 72 años desaparecid..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get rid of accents\n",
    "def clean_accent(header_str):\n",
    "    return header_str.replace('á','a').replace('é','e').replace('í','i').replace('ó','o').replace('ú','u')\n",
    "#df = df.replace({' ': ''}, regex=True)\n",
    "\n",
    "dfnews_raw2 = pd.DataFrame(dfnews_raw['Headers'].apply(clean_accent))\n",
    "dfnews_raw2.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Un paracaidista cae a un tejado en el encuentr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un accidente entre un coche y una moto se sald...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Un hombre sufre varios traumatismos graves al ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desarticulado un grupo criminal que se dedicab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Herido muy grave un hombre invidente y sordomu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La sentencia del Supremo a 'La Manada' reaviva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Localizado el argentino de 72 años desaparecid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headers\n",
       "0  Un paracaidista cae a un tejado en el encuentr...\n",
       "1  Un accidente entre un coche y una moto se sald...\n",
       "2  Un hombre sufre varios traumatismos graves al ...\n",
       "3  Desarticulado un grupo criminal que se dedicab...\n",
       "4  Herido muy grave un hombre invidente y sordomu...\n",
       "5  La sentencia del Supremo a 'La Manada' reaviva...\n",
       "6  Localizado el argentino de 72 años desaparecid..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get rid of commas\n",
    "def clean_commas(header_str):\n",
    "    return header_str.replace(',','')\n",
    "\n",
    "dfnews_raw3 = pd.DataFrame(dfnews_raw2['Headers'].apply(clean_accent))\n",
    "dfnews_raw3.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: Headers...>\n"
     ]
    }
   ],
   "source": [
    "# Get each word / Tokenizar\n",
    "def token(header_str):\n",
    "    return nltk.word_tokenize(header_str)\n",
    "\n",
    "token_dfnews = pd.DataFrame(dfnews_raw3['Headers'].apply(token))\n",
    "token_dfnews.head(7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a422174de016>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstopWords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spanish'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('spanish'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estas', 'todo', 'qué', 'habremos', 'sentida', 'tendría', 'nosotros', 'estéis', 'y', 'teníamos', 'sean', 'algunas', 'haya', 'estará', 'estuviesen', 'estados', 'al', 'esas', 'estemos', 'tendrás', 'tuviesen', 'hay', 'hubieras', 'tengas', 'sentidas', 'donde', 'poco', 'soy', 'no', 'estuvieses', 'quien', 'fueras', 'hubieseis', 'hubiésemos', 'mí', 'tu', 'todos', 'o', 'habíais', 'tuviera', 'habido', 'habidos', 'entre', 'lo', 'estuvieseis', 'las', 'nuestras', 'habiendo', 'estén', 'estaríais', 'ese', 'eran', 'sintiendo', 'estarán', 'esté', 'fueseis', 'eso', 'eras', 'hubiste', 'estadas', 'hubierais', 'habrán', 'estamos', 'hubiese', 'míos', 'una', 'estarías', 'sentido', 'fuimos', 'otras', 'sentid', 'estés', 'unos', 'tengo', 'nada', 'estoy', 'estos', 'tiene', 'cuando', 'tendrá', 'sea', 'su', 'erais', 'tuvieron', 'sí', 'hubiéramos', 'tuviste', 'era', 'estarás', 'la', 'habrías', 'estaban', 'estás', 'estabas', 'vosostras', 'hubisteis', 'ya', 'sois', 'fuiste', 'tuvierais', 'habías', 'habré', 'tenidas', 'habíamos', 'seáis', 'seríais', 'habían', 'tuviéramos', 'en', 'habida', 'seréis', 'tenido', 'estando', 'seamos', 'fueses', 'uno', 'de', 'me', 'esos', 'tendrían', 'vuestros', 'por', 'fuera', 'seríamos', 'tendréis', 'tenías', 'nos', 'muy', 'habrá', 'estuviese', 'tendremos', 'ante', 'tanto', 'mías', 'les', 'tendré', 'suyos', 'ellos', 'quienes', 'tenía', 'tuve', 'estabais', 'estuvierais', 'los', 'cual', 'estuve', 'teniendo', 'tuyo', 'seremos', 'fuerais', 'le', 'te', 'habría', 'tuyas', 'del', 'más', 'contra', 'fuese', 'hayas', 'mi', 'vuestro', 'tenga', 'siente', 'con', 'estuvieras', 'tienen', 'serías', 'fuisteis', 'hube', 'este', 'éramos', 'como', 'desde', 'seré', 'muchos', 'tenían', 'hayáis', 'suyo', 'ti', 'nuestro', 'teníais', 'esto', 'habidas', 'será', 'os', 'él', 'fueran', 'mucho', 'fui', 'hubo', 'estuvieron', 'tuvisteis', 'a', 'yo', 'nuestros', 'mío', 'habrían', 'mis', 'seas', 'estábamos', 'estuvo', 'está', 'tendrán', 'hubieses', 'hayan', 'nosotras', 'tenemos', 'había', 'fue', 'habríamos', 'serás', 'otra', 'tenida', 'hasta', 'habríais', 'estuviéramos', 'tuvo', 'estuvimos', 'ha', 'tuvieran', 'tuviese', 'ellas', 'tenidos', 'otro', 'fuéramos', 'tengamos', 'tuvieras', 'están', 'eres', 'habréis', 'sentidos', 'otros', 'estad', 'estar', 'estado', 'algo', 'sin', 'han', 'vosostros', 'estáis', 'tuyos', 'es', 'tenéis', 'tienes', 'tengáis', 'fueron', 'durante', 'también', 'serían', 'estaríamos', 'estaré', 'somos', 'fuésemos', 'hubimos', 'tengan', 'tendríais', 'hubiera', 'tuvimos', 'un', 'he', 'vuestras', 'se', 'tuviésemos', 'porque', 'estuviste', 'tendríamos', 'estaréis', 'hemos', 'para', 'nuestra', 'que', 'hubiesen', 'tus', 'estuvieran', 'habéis', 'ni', 'tú', 'tendrías', 'tuvieseis', 'estaremos', 'ella', 'son', 'habrás', 'estarían', 'estuvisteis', 'sería', 'hubieron', 'mía', 'serán', 'hayamos', 'vuestra', 'tened', 'algunos', 'estada', 'el', 'sus', 'estuviera', 'hubieran', 'esta', 'estaría', 'has', 'suyas', 'estuviésemos', 'estaba', 'antes', 'e', 'esa', 'tuya', 'sobre', 'fuesen', 'tuvieses', 'suya', 'pero'}\n"
     ]
    }
   ],
   "source": [
    "print(stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stopwords(list_tokens):\n",
    "    for token in list_tokens:\n",
    "        for word in stopWords:\n",
    "            if word == token:\n",
    "                list_tokens.remove(word)\n",
    "    return list_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = ['todo','es','un','caca','no','me','toques','los','cojones']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['es', 'caca', 'me', 'toques', 'cojones']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Un, paracaidista, cae, un, tejado, el, encuen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Un, accidente, un, coche, una, moto, salda, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Un, hombre, sufre, varios, traumatismos, grav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Desarticulado, grupo, criminal, se, dedicaba,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Herido, grave, hombre, invidente, sordomudo, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headers\n",
       "0  [Un, paracaidista, cae, un, tejado, el, encuen...\n",
       "1  [Un, accidente, un, coche, una, moto, salda, u...\n",
       "2  [Un, hombre, sufre, varios, traumatismos, grav...\n",
       "3  [Desarticulado, grupo, criminal, se, dedicaba,...\n",
       "4  [Herido, grave, hombre, invidente, sordomudo, ..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_dfnews = pd.DataFrame(token_dfnews['Headers'].apply(clean_stopwords))\n",
    "clean_dfnews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are imported for you. If you prefer to use additional libraries feel free to uncomment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "# from lxml import html\n",
    "# from lxml.html import fromstring\n",
    "# import urllib.request\n",
    "# from urllib.request import urlopen\n",
    "# import random\n",
    "# import re\n",
    "# import scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "# Obtenemos la respuesta de la url\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parseamos a html la respuesta y la pasamos a texto\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Achicamos la b√∫squeda al contenedor que contiene a todos los developers\n",
    "developers_container = soup.find(\"div\", {'class': 'col-md-9'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Achicamos la b√∫squeda a cada dato del developer: name, user, description\n",
    "name_html = developers_container.find_all(\"h1\", {'class': 'h3 lh-condensed'})\n",
    "user_html = developers_container.find_all(\"a\", {'class': 'link-gray'})\n",
    "description_html = developers_container.find_all(\"div\", {'class': 'f6 text-gray mt-1'})\n",
    "# pprint(name_html)\n",
    "# pprint(user_html)\n",
    "# pprint(description_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 25, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name_html), len(user_html), len(description_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Michiel Borkent',\n",
      " 'Kevin Papst',\n",
      " 'William Candillon',\n",
      " 'Magnus Edenhill',\n",
      " 'James Newton-King',\n",
      " 'Orta',\n",
      " 'Samuel Colvin',\n",
      " 'Anthony Scopatz',\n",
      " 'Aleksey Kladov',\n",
      " 'Erik Rasmussen',\n",
      " 'Jonah Williams',\n",
      " 'V√≠tor Galv√£o',\n",
      " 'Hiranya Jayathilaka',\n",
      " 'Mr.doob',\n",
      " 'Jared Palmer',\n",
      " 'Matthew Mueller',\n",
      " 'radare',\n",
      " 'greatghoul',\n",
      " 'Sarah Drasner',\n",
      " 'Kent C. Dodds',\n",
      " 'Joel Denning',\n",
      " 'Thomas Steur',\n",
      " 'Ben Newman',\n",
      " 'Michael Dowling',\n",
      " 'Vladimir Mihailenco']\n",
      "['borkdude',\n",
      " 'kevinpapst',\n",
      " 'wcandillon',\n",
      " 'edenhill',\n",
      " 'JamesNK',\n",
      " 'orta',\n",
      " 'samuelcolvin',\n",
      " 'scopatz',\n",
      " 'matklad',\n",
      " 'erikras',\n",
      " 'jonahwilliams',\n",
      " 'vitorgalvao',\n",
      " 'hiranya911',\n",
      " 'mrdoob',\n",
      " 'jaredpalmer',\n",
      " 'matthewmueller',\n",
      " 'radare',\n",
      " 'greatghoul',\n",
      " 'sdras',\n",
      " 'kentcdodds',\n",
      " 'joeldenning',\n",
      " 'tsteur',\n",
      " 'benjamn',\n",
      " 'mtdowling',\n",
      " 'vmihailenco']\n",
      "['A minimal and opinionated linter for Clojure code that sparks joy.',\n",
      " 'Kimai v2 is a web-based multiuser time-tracking application. Free for '\n",
      " 'everyone: freelancers, agencies and companies track their employee '\n",
      " 'working-times and generate invoices.',\n",
      " 'Image Cache for React Native',\n",
      " 'The Apache Kafka C/C++ library',\n",
      " 'Json.NET is a popular high-performance JSON framework for .NET',\n",
      " 'Simplify your iOS/Mac analytics',\n",
      " 'Data parsing using Python type hinting',\n",
      " 'Improved Nano Syntax Highlighting Files',\n",
      " 'Rust library for single assignment cells and lazy statics without macros',\n",
      " 'A starter boilerplate for a universal webapp using express, react, redux, '\n",
      " 'webpack, and react-transform',\n",
      " 'Immutable, persistent data structures for Dart and Flutter.',\n",
      " 'Collection of Alfred workflows',\n",
      " 'An implementation of the MDCC (Multi-Data Center Commit) Protocol featuring '\n",
      " 'Fast Paxos.',\n",
      " 'JavaScript 3D library.',\n",
      " 'Build forms in React, without the tears üò≠',\n",
      " 'The next web scraper. See through the <html> noise.',\n",
      " 'unix-like reverse engineering framework and commandline tools',\n",
      " 'Êî∂ÈõÜÊï¥ÁêÜËøúÁ®ãÂ∑•‰ΩúÁõ∏ÂÖ≥ÁöÑËµÑÊñô',\n",
      " 'A curated list of awesome actions to use on GitHub',\n",
      " 'üîÄ Cross platform setting of environment scripts',\n",
      " 'A simple example of how to use webpack with single-spa',\n",
      " 'Backup of seventag when it was still open source',\n",
      " 'JavaScript syntax tree transformer, nondestructive pretty-printer, and '\n",
      " 'automatic source map generator',\n",
      " 'CRON for PHP: Calculate the next or previous run date and determine if a '\n",
      " 'CRON expression is due',\n",
      " 'msgpack.org[Go] MessagePack encoding for Golang']\n"
     ]
    }
   ],
   "source": [
    "# Creamos una lista para cada elemento\n",
    "names = [name.text for name in name_html]\n",
    "users = [user.text for user in user_html]\n",
    "descriptions = [description.text.strip() for description in description_html] # Le he hechs strip porque ten√≠a espacios.\n",
    "\n",
    "# Imprimimos las listas, con salto de l√≠nea.\n",
    "pprint(names)\n",
    "pprint(users)\n",
    "pprint(descriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>User</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michiel Borkent</td>\n",
       "      <td>borkdude</td>\n",
       "      <td>A minimal and opinionated linter for Clojure c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kevin Papst</td>\n",
       "      <td>kevinpapst</td>\n",
       "      <td>Kimai v2 is a web-based multiuser time-trackin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>William Candillon</td>\n",
       "      <td>wcandillon</td>\n",
       "      <td>Image Cache for React Native</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Magnus Edenhill</td>\n",
       "      <td>edenhill</td>\n",
       "      <td>The Apache Kafka C/C++ library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James Newton-King</td>\n",
       "      <td>JamesNK</td>\n",
       "      <td>Json.NET is a popular high-performance JSON fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Orta</td>\n",
       "      <td>orta</td>\n",
       "      <td>Simplify your iOS/Mac analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Samuel Colvin</td>\n",
       "      <td>samuelcolvin</td>\n",
       "      <td>Data parsing using Python type hinting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Anthony Scopatz</td>\n",
       "      <td>scopatz</td>\n",
       "      <td>Improved Nano Syntax Highlighting Files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aleksey Kladov</td>\n",
       "      <td>matklad</td>\n",
       "      <td>Rust library for single assignment cells and l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Erik Rasmussen</td>\n",
       "      <td>erikras</td>\n",
       "      <td>A starter boilerplate for a universal webapp u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jonah Williams</td>\n",
       "      <td>jonahwilliams</td>\n",
       "      <td>Immutable, persistent data structures for Dart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>V√≠tor Galv√£o</td>\n",
       "      <td>vitorgalvao</td>\n",
       "      <td>Collection of Alfred workflows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hiranya Jayathilaka</td>\n",
       "      <td>hiranya911</td>\n",
       "      <td>An implementation of the MDCC (Multi-Data Cent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mr.doob</td>\n",
       "      <td>mrdoob</td>\n",
       "      <td>JavaScript 3D library.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jared Palmer</td>\n",
       "      <td>jaredpalmer</td>\n",
       "      <td>Build forms in React, without the tears üò≠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Matthew Mueller</td>\n",
       "      <td>matthewmueller</td>\n",
       "      <td>The next web scraper. See through the &lt;html&gt; n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>radare</td>\n",
       "      <td>radare</td>\n",
       "      <td>unix-like reverse engineering framework and co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>greatghoul</td>\n",
       "      <td>greatghoul</td>\n",
       "      <td>Êî∂ÈõÜÊï¥ÁêÜËøúÁ®ãÂ∑•‰ΩúÁõ∏ÂÖ≥ÁöÑËµÑÊñô</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sarah Drasner</td>\n",
       "      <td>sdras</td>\n",
       "      <td>A curated list of awesome actions to use on Gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kent C. Dodds</td>\n",
       "      <td>kentcdodds</td>\n",
       "      <td>üîÄ Cross platform setting of environment scripts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Joel Denning</td>\n",
       "      <td>joeldenning</td>\n",
       "      <td>A simple example of how to use webpack with si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Thomas Steur</td>\n",
       "      <td>tsteur</td>\n",
       "      <td>Backup of seventag when it was still open source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ben Newman</td>\n",
       "      <td>benjamn</td>\n",
       "      <td>JavaScript syntax tree transformer, nondestruc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Michael Dowling</td>\n",
       "      <td>mtdowling</td>\n",
       "      <td>CRON for PHP: Calculate the next or previous r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Vladimir Mihailenco</td>\n",
       "      <td>vmihailenco</td>\n",
       "      <td>msgpack.org[Go] MessagePack encoding for Golang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name            User  \\\n",
       "0       Michiel Borkent        borkdude   \n",
       "1           Kevin Papst      kevinpapst   \n",
       "2     William Candillon      wcandillon   \n",
       "3       Magnus Edenhill        edenhill   \n",
       "4     James Newton-King         JamesNK   \n",
       "5                  Orta            orta   \n",
       "6         Samuel Colvin    samuelcolvin   \n",
       "7       Anthony Scopatz         scopatz   \n",
       "8        Aleksey Kladov         matklad   \n",
       "9        Erik Rasmussen         erikras   \n",
       "10       Jonah Williams   jonahwilliams   \n",
       "11         V√≠tor Galv√£o     vitorgalvao   \n",
       "12  Hiranya Jayathilaka      hiranya911   \n",
       "13              Mr.doob          mrdoob   \n",
       "14         Jared Palmer     jaredpalmer   \n",
       "15      Matthew Mueller  matthewmueller   \n",
       "16               radare          radare   \n",
       "17           greatghoul      greatghoul   \n",
       "18        Sarah Drasner           sdras   \n",
       "19        Kent C. Dodds      kentcdodds   \n",
       "20         Joel Denning     joeldenning   \n",
       "21         Thomas Steur          tsteur   \n",
       "22           Ben Newman         benjamn   \n",
       "23      Michael Dowling       mtdowling   \n",
       "24  Vladimir Mihailenco     vmihailenco   \n",
       "\n",
       "                                          Description  \n",
       "0   A minimal and opinionated linter for Clojure c...  \n",
       "1   Kimai v2 is a web-based multiuser time-trackin...  \n",
       "2                        Image Cache for React Native  \n",
       "3                      The Apache Kafka C/C++ library  \n",
       "4   Json.NET is a popular high-performance JSON fr...  \n",
       "5                     Simplify your iOS/Mac analytics  \n",
       "6              Data parsing using Python type hinting  \n",
       "7             Improved Nano Syntax Highlighting Files  \n",
       "8   Rust library for single assignment cells and l...  \n",
       "9   A starter boilerplate for a universal webapp u...  \n",
       "10  Immutable, persistent data structures for Dart...  \n",
       "11                     Collection of Alfred workflows  \n",
       "12  An implementation of the MDCC (Multi-Data Cent...  \n",
       "13                             JavaScript 3D library.  \n",
       "14          Build forms in React, without the tears üò≠  \n",
       "15  The next web scraper. See through the <html> n...  \n",
       "16  unix-like reverse engineering framework and co...  \n",
       "17                                      Êî∂ÈõÜÊï¥ÁêÜËøúÁ®ãÂ∑•‰ΩúÁõ∏ÂÖ≥ÁöÑËµÑÊñô  \n",
       "18  A curated list of awesome actions to use on Gi...  \n",
       "19    üîÄ Cross platform setting of environment scripts  \n",
       "20  A simple example of how to use webpack with si...  \n",
       "21   Backup of seventag when it was still open source  \n",
       "22  JavaScript syntax tree transformer, nondestruc...  \n",
       "23  CRON for PHP: Calculate the next or previous r...  \n",
       "24    msgpack.org[Go] MessagePack encoding for Golang  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usamos zip y list para juntar los elementos en una lista de listas que contenga la info de los developers.\n",
    "developers_info = list(zip(names, users, descriptions))\n",
    "# Los volcamos a un dataframe.\n",
    "import pandas as pd\n",
    "developers_df = pd.DataFrame(developers_info)\n",
    "developers_df.columns = ['Name', 'User', 'Description']\n",
    "developers_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (Á•ûÊ•ΩÂùÇË¶ö„ÄÖ)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Michiel Borkent (borkdude)',\n",
       " 'Kevin Papst (kevinpapst)',\n",
       " 'William Candillon (wcandillon)',\n",
       " 'Magnus Edenhill (edenhill)',\n",
       " 'James Newton-King (JamesNK)',\n",
       " 'Orta (orta)',\n",
       " 'Samuel Colvin (samuelcolvin)',\n",
       " 'Anthony Scopatz (scopatz)',\n",
       " 'Aleksey Kladov (matklad)',\n",
       " 'Erik Rasmussen (erikras)',\n",
       " 'Jonah Williams (jonahwilliams)',\n",
       " 'V√≠tor Galv√£o (vitorgalvao)',\n",
       " 'Hiranya Jayathilaka (hiranya911)',\n",
       " 'Mr.doob (mrdoob)',\n",
       " 'Jared Palmer (jaredpalmer)',\n",
       " 'Matthew Mueller (matthewmueller)',\n",
       " 'radare (radare)',\n",
       " 'greatghoul (greatghoul)',\n",
       " 'Sarah Drasner (sdras)',\n",
       " 'Kent C. Dodds (kentcdodds)',\n",
       " 'Joel Denning (joeldenning)',\n",
       " 'Thomas Steur (tsteur)',\n",
       " 'Ben Newman (benjamn)',\n",
       " 'Michael Dowling (mtdowling)',\n",
       " 'Vladimir Mihailenco (vmihailenco)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "# Me he adelantado en el apartado anterior. Lo saco con el formato pedido (lista de strings).\n",
    "def concat(lista):\n",
    "    \"\"\"\n",
    "    Concatena el primer y segundo elemento de una lista, poniendo el segundo elemento entre par√©ntesis\n",
    "    \"\"\"\n",
    "    return lista[0] + \" (\" + lista[1] + \")\"\n",
    "\n",
    "developers_names = [concat(developer) for developer in developers_info]\n",
    "developers_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "# Hago lo mismo pero con la p√°gina de repos\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_container = soup.find(\"div\", {'class': 'col-md-9'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Achicamos la b√∫squeda a cada dato del developer: name, user, description\n",
    "repo_html = repo_container.find_all(\"h1\", {'class': 'h3 lh-condensed'})\n",
    "# pprint(repo_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CorentinJ / Real-Time-Voice-Cloning',\n",
       " 'allegroai / trains',\n",
       " '521xueweihan / HelloGitHub',\n",
       " 'open-mmlab / mmaction',\n",
       " 'kimiyoung / transformer-xl',\n",
       " 'foxlet / macOS-Simple-KVM',\n",
       " 'ansible / awx',\n",
       " 'open-mmlab / mmdetection',\n",
       " 'spulec / moto',\n",
       " 'marshmallow-code / marshmallow',\n",
       " 'princewen / tensorflow_practice',\n",
       " 'scikit-learn / scikit-learn',\n",
       " 'facebookresearch / pyrobot',\n",
       " 'google-research / google-research',\n",
       " 'chakki-works / doccano',\n",
       " 'CyberZHG / keras-bert',\n",
       " 'leisurelicht / wtfpython-cn',\n",
       " 'oppia / oppia',\n",
       " 'huggingface / pytorch-pretrained-BERT',\n",
       " 'luong-komorebi / Awesome-Linux-Software',\n",
       " 'google-research / bert',\n",
       " 'xinntao / EDVR',\n",
       " 'YunYang1994 / tensorflow-yolov3',\n",
       " 'IDSIA / sacred',\n",
       " 'fizyr / keras-retinanet']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos = [repo.text.strip() for repo in repo_html]\n",
    "repos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the date, days, title, city, country of next 25 hackathon events as a Pandas dataframe table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://hackevents.co/hackathons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of tweets by a given Twitter account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** in case account/s name not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = city=input('Enter the city:')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from Scraping import get_all_comments_from_subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting posts from /r/askreddit...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0qaj7/have_you_ever_quit_a_job_without_another_lined_up/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0ocp5/it_people_of_reddit_what_is_your_goto_generic/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0matc/which_two_and_two_did_you_just_recently_put/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0kwdw/teachers_of_reddit_what_is_the_weirdest_excuse/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0kyo0/americans_whove_visited_european_countries_what/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0liuk/liberals_of_reddit_what_is_your_most_conservative/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0n5pd/its_a_post_apocalyptic_world_however_reddit_is/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0ovb8/serious_doctor_of_reddit_what_was_the_saddest/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0ijuy/teachers_of_reddit_what_are_some_of_the_weirdest/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0oyfb/an_alien_is_trying_to_impersonate_you_and_looks/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0pt9o/serious_whats_something_harmless_your_parents_did/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0ia83/which_movie_villain_would_be_considered_a_hero_in/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0iqzu/what_happened_at_your_school_that_shocks_you_to/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0i0o1/what_illegal_thing_would_you_do_as_soon_as_its/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0rjaa/what_is_the_worst_feeling_that_isnt_pain/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0gzqf/if_you_won_10_million_what_are_literally_the/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0lv2m/if_you_had_a_warning_label_what_would_it_say/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0ni9t/gamers_of_reddit_you_are_placed_into_an_arcade/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0ijdo/if_humans_were_kept_as_pets_by_another_species/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0kml2/redditors_what_made_you_go_thank_god_i_broke_up/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0sifa/substitute_teachers_of_reddit_whats_the_hardest/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0tyde/high_rise_window_cleaners_what_have_you/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0u9up/redditors_who_are_you_and_what_do_you_do/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0pshh/women_of_reddit_what_is_the_biggest_mistake_guys/.json...\n",
      "Getting comments from https://reddit.com/r/AskReddit/comments/c0k8p6/what_do_you_get_complimented_for_the_most/.json...\n"
     ]
    }
   ],
   "source": [
    "subreddit_url = \"/r/askreddit\" #https://reddit.com/r/askreddit\n",
    "comments = get_all_comments_from_subreddit(subreddit_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-pre procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Worked a call center job after one week of tra...</td>\n",
       "      <td>3350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yep.\\n\\nMy mental health is still not good, an...</td>\n",
       "      <td>5779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quit my job at a call centre without anything ...</td>\n",
       "      <td>9938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Left my job of 15 years with nothing lined up ...</td>\n",
       "      <td>5582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hell yes.  I worked in a retail store that was...</td>\n",
       "      <td>14335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  score\n",
       "0  Worked a call center job after one week of tra...   3350\n",
       "1  Yep.\\n\\nMy mental health is still not good, an...   5779\n",
       "2  Quit my job at a call centre without anything ...   9938\n",
       "3  Left my job of 15 years with nothing lined up ...   5582\n",
       "4  Hell yes.  I worked in a retail store that was...  14335"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(comments)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Valve released Steam. \\n\\nTook me entirely too...</td>\n",
       "      <td>34514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>A sugar glider. Kept hearing a high pitched sq...</td>\n",
       "      <td>27213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>In Spanish, hats are called \"sombrero\" because...</td>\n",
       "      <td>26416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Fyre Festival VIP suites</td>\n",
       "      <td>24608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>I race cars in an amateur league. There is a b...</td>\n",
       "      <td>22677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  score\n",
       "96   Valve released Steam. \\n\\nTook me entirely too...  34514\n",
       "475  A sugar glider. Kept hearing a high pitched sq...  27213\n",
       "77   In Spanish, hats are called \"sombrero\" because...  26416\n",
       "998                           Fyre Festival VIP suites  24608\n",
       "78   I race cars in an amateur league. There is a b...  22677"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['score'], inplace=True, ascending=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My babysitter became basically family. She was an old woman and took care of us for like 20 years, before I was even born she cared for my siblings. One morning she didn't show up to work. Didn't call. Nothing.\\n\\nSame thing the next morning. My mom went to her house and found she had passed away. She came home and told us kids. We asked a few questions. How did you find her? Well she died in her car. Oh. Okay... She must have just died of old age, she was like 74 after all.\\n\\nYears later I figured it out. Like 13 years. I was telling a friend about who she was and what she meant to our family. Then it hit me.. like a ton of bricks.\\n\\nPeople don't just die randomly one morning sitting in their car at their house. Their bodies don't just shut down. She commit suicide at the age of 70-something by carbon monoxide poisoning. She turned the car on in a closed garage and ended her life. My parents didn't want to tell me or my siblings because they didn't want it to impact how we thought of her and what she meant to us as a family. She suffered from severe depression all her life and as a kid I had no idea. It is truly heartbreaking because we loved her like a grandma. I wish she were still around.\\n\\nWe are still friends with her sister who is in her mid-90s, so our baby sitter could still be here too. If you're suffering, talk to someone, because there are people who will want you around tomorrow and 20 years from now.\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1610"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 : chachipistachi    When I was in 3rd grade I was late to school because my dog had puppies inside a hollow log in the woods beside my house, and I was the only one small enough to crawl inside and get the puppies out. \n",
      "\n",
      "Obligatory Puppy Photo, circa 1993 (explaining my horrible outfit, but not necessarily justifying it:)\n",
      "\n",
      "[https://imgur.com/Cdch5iS](https://imgur.com/Cdch5iS)\n",
      "438 : chachipistachi    Pediatrician. Do not read if you don’t like hearing about kids dying — I have 2 I will never forget\n",
      "\n",
      "1: 5 year old with [congenital lupus](https://www.ncbi.nlm.nih.gov/m/pubmed/15035648/) who had never received care due to family’s religious beliefs. Went down (likely heart stopped) in neighbor’s backyard — brought in by ambulance (neighbor didn’t realize parent’s religious convictions). I was working my ICU month. Kid was in full blown kidney failure. Only option we had, aside from continuous dialysis, was transplant. Parents refused. Said God would heal the child. Refused to let us do anything. Kid coded and family refused intervention, so we had to watch the kid die — we were unable to get a court order to intervene prior to the kid coding. \n",
      "\n",
      "2: I was working hospital and we had a recurring patient, a teenager, who had progressively worsening symptoms. Started with the eyes — blurry vision. Then difficulty swallowing — [achalasia](https://my.clevelandclinic.org/health/diseases/17534-achalasia-overview-swallowing-problems). Respiratory issues. Bowel obstruction that lead to complete death of the colon. And so on. Could not figure out why this was happening, despite extensive testing. Patient finally came in one day, about a year after initial presentation, after being found face-down in the family pool — heart had stopped (no water in the lungs). Withdrew care after 48 hrs and confirmed brain death. Autopsy came back 3+ years later with abnormally high arsenic levels. Kid had been poisoned. The death was awful but finding out we somehow missed the poisoning despite testing for it was heartbreaking for all of us\n",
      "482 : chachipistachi    It wasn't exactly a confiscation. Some of my students thought it would be a good idea to bring me two chickens. Two live chickens. They knew my daughter had a pet duck that had recently died, so this was their idea to help us get past the grief. I had to keep them in a carrier in my classroom closet in the dark just so they would be quiet. (The chickens, not the kids).  By the end of the day I found a kid with a grandmother that had a farm. She took the chickens home.\n",
      "Edit: Here's her duck in better days. https://i.imgur.com/5ZYs6Wl.jpg\n",
      "511 : chachipistachi    In grade school I had two really close friends named Juan and Nick. [Here is a picture of us](https://i.imgur.com/Kv9IWWf.jpg) that I love with me in the front, then Juan, and then Nick. The three of us were really close and bonded of our shared nerdy interests of reading, Star Wars, and The Simpsons. We also really enjoyed drawing.\n",
      "\n",
      "I don't remember how it started exactly, but we ended up making this notebook that we passed back and forth between us. It was a comic about a guy named Tom and his cat. We would each take turns doing a strip of a few panels and then hand it over. [Here is a quick drawing I did of Tom on my phone](https://i.imgur.com/atgHmod.png) so you can get an idea of what he looked like. The comic was about the everyday life of Tom and it was extremely mundane. It was things like Tom tries to decide on a shirt or Tom dropped the cat food on the floor. It was really dumb stuff, but the three of us found it so hilarious because we were weird kids.\n",
      "\n",
      "One day our teacher caught us with the notebook and confiscated it from us. She never said a word about it, but I bet when she looked through that thing she probably thought it was the weirdest fucking thing ever, especially since we were laughing hysterically at it when she took it from us.\n",
      "672 : chachipistachi    Any time I would cry or express anger, I would be teased for being upset.\n",
      " \"Awwwww she's mad!!!! Awwwww waaaahhhwahhhhhwahhhh aww booo hoooooo\" \n",
      "I ended up shutting down and finding unhealthy ways to cope that eventually plagued my life in more ways than one.\n",
      "766 : chachipistachi    [Johnny from The Karate Kid](https://youtu.be/C_Gz_iTuRMM)\n",
      "785 : chachipistachi    A boy slipped on some ice and got run over by a school bus when I was in 2nd grade in front of the whole school. Miraculously, he survived and is doing well to this day.\n",
      "\n",
      "Edit: Here’s a news story from the time about it. https://www.google.com/url?sa=i&amp;source=web&amp;cd=&amp;ved=2ahUKEwi-q7Gr3OniAhWMwFkKHTq6AzEQzPwBegQIARAC&amp;url=https%3A%2F%2Fwww.deseretnews.com%2Farticle%2F881332%2FA-miracle-Boy-is-recovering-from-bus-run-in.html&amp;psig=AOvVaw0nrEz0u4xo-HO8wGJrYW7A&amp;ust=1560627424520302\n",
      "810 : chachipistachi    There was somebody living across the street from my high school who was a bomb maker that was plotting to blow one his bombs up at a 4th of July celebration in the next year or two .\n",
      "\n",
      "I have no idea why the fuck he was acquitted.\n",
      "\n",
      "I just remember seeing a shit ton of cop cars and FBI vehicles. \n",
      "\n",
      "https://www.google.com/amp/s/amp.usatoday.com/amp/31570845\n",
      "811 : chachipistachi    A guy in our ethnic studies class went to the middle east to become a terrorist and got intercepted by the FBI.\n",
      "\n",
      "He was in my high school. Didn't know where he went to college.\n",
      "\n",
      "[Source](https://www.nytimes.com/2016/04/10/us/parents-face-limited-options-to-keep-children-from-terrorism.html)\n",
      "\n",
      "“I just hope Allah doesn’t take my soul until I have at least, like, a couple gallons of blood that I’ve spilled for him\"\n",
      "\n",
      "Like what the fuck\n",
      "860 : chachipistachi    I would flip off a horse while it's passing me, which is currently illegal.\n",
      "\n",
      "https://www.law.cornell.edu/cfr/text/36/2.16\n",
      "997 : chachipistachi    Isn't there a certain nearly-defeated group of international terrorists who'd like their little caliphate back? Aren't they a bit strapped for cash right now?\n",
      "\n",
      "Yeah. That'd be literally the worst way.\n",
      "\n",
      "&amp;#x200B;\n",
      "\n",
      "^(Edit: Well that blew up. So if anyone's wondering, in the real world, they're) [^(not really strapped for cash at all)](https://www.theatlantic.com/international/archive/2019/03/isis-caliphate-money-territory/584911/)^(, and it's going to take years to actually defeat them.)\n",
      "1037 : chachipistachi    [https://www.thesun.co.uk/news/8402541/how-national-lottery-lout-michael-carroll-blew-9-7m-pounds/](https://www.thesun.co.uk/news/8402541/how-national-lottery-lout-michael-carroll-blew-9-7m-pounds/)\n",
      "\n",
      "&amp;#x200B;\n",
      "\n",
      "this actually happend in the UK (although it may be arguble he had a \"good time\")\n",
      "\n",
      "&amp;#x200B;\n",
      "\n",
      "was poor &gt; won 10m &gt; he's now broke i believe\n",
      "1308 : chachipistachi    When his mom came over to my house drunk off her ass demanding back a stuffed animal he gave me.  She threatened to have me arrested for theft.\n",
      "\n",
      "Restraining orders are friggen magical, guys.\n",
      "\n",
      "EDIT: sentence structure.\n",
      "\n",
      "EDIT 2: [Link to the full story](https://www.reddit.com/r/entitledparents/comments/aqufup/of_oedipal_mothers_and_giant_teddy_bears/)\n",
      "1396 : chachipistachi    Imagine getting [this](https://memestatic.fjcdn.com/pictures/Pretty+sure+ive+yelled+your+name+while+vomiting_4215fc_6937685.jpg) kid as a new teacher.\n",
      "1418 : chachipistachi    here's a few things you might expect to [see]  (https://youtu.be/sfmAeijj5cM).\n",
      "1593 : chachipistachi    [Karmas](https://www.karmalb.com/user/Iam4real)\n"
     ]
    }
   ],
   "source": [
    "chachipistachi = []\n",
    "for i in range(df.shape[0]):\n",
    "    if 'http' in df['content'][i]:\n",
    "        chachipistachi.append(df['content'][i])\n",
    "        print(str(i) + ' : chachipistachi    ' + df['content'][i])\n",
    "    elif 'www' in df['content'][i]:\n",
    "        chachipistachi.append(df['content'][i])\n",
    "        print(str(i) + ' : chachipistachi    ' + df['content'][i])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(chachipistachi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Valve released Steam. \\n\\nTook me entirely too...</td>\n",
       "      <td>34514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>A sugar glider. Kept hearing a high pitched sq...</td>\n",
       "      <td>27213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>In Spanish, hats are called \"sombrero\" because...</td>\n",
       "      <td>26416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Fyre Festival VIP suites</td>\n",
       "      <td>24608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>I race cars in an amateur league. There is a b...</td>\n",
       "      <td>22677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  score\n",
       "96   Valve released Steam. \\n\\nTook me entirely too...  34514\n",
       "475  A sugar glider. Kept hearing a high pitched sq...  27213\n",
       "77   In Spanish, hats are called \"sombrero\" because...  26416\n",
       "998                           Fyre Festival VIP suites  24608\n",
       "78   I race cars in an amateur league. There is a b...  22677"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'] = df['content'].str.replace('\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Valve released Steam \\n\\nTook me entirely too ...</td>\n",
       "      <td>34514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>A sugar glider Kept hearing a high pitched squ...</td>\n",
       "      <td>27213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>In Spanish hats are called sombrero because th...</td>\n",
       "      <td>26416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Fyre Festival VIP suites</td>\n",
       "      <td>24608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>I race cars in an amateur league There is a bl...</td>\n",
       "      <td>22677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  score\n",
       "96   Valve released Steam \\n\\nTook me entirely too ...  34514\n",
       "475  A sugar glider Kept hearing a high pitched squ...  27213\n",
       "77   In Spanish hats are called sombrero because th...  26416\n",
       "998                           Fyre Festival VIP suites  24608\n",
       "78   I race cars in an amateur league There is a bl...  22677"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'] = df['content'].str.replace(r'[^\\w\\s]','')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672 : chachipistachi    Any time I would cry or express anger I would be teased for being upset\n",
      " Awwwww shes mad Awwwww waaaahhhwahhhhhwahhhh aww booo hoooooo \n",
      "I ended up shutting down and finding unhealthy ways to cope that eventually plagued my life in more ways than one\n"
     ]
    }
   ],
   "source": [
    "# Verificamos si hemos eliminado los comentarios que contienen 'url'\n",
    "\n",
    "chachipistachi = []\n",
    "for i in range(df.shape[0]):\n",
    "    if 'http' in df['content'][i]:\n",
    "        chachipistachi.append(df['content'][i])\n",
    "        print(str(i) + ' : chachipistachi    ' + df['content'][i])\n",
    "    elif 'www' in df['content'][i]:\n",
    "        chachipistachi.append(df['content'][i])\n",
    "        print(str(i) + ' : chachipistachi    ' + df['content'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(chachipistachi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/isi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[Valve, released, Steam, Took, me, entirely, t...</td>\n",
       "      <td>34514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>[A, sugar, glider, Kept, hearing, a, high, pit...</td>\n",
       "      <td>27213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>[In, Spanish, hats, are, called, sombrero, bec...</td>\n",
       "      <td>26416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[Fyre, Festival, VIP, suites]</td>\n",
       "      <td>24608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[I, race, cars, in, an, amateur, league, There...</td>\n",
       "      <td>22677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  score\n",
       "96   [Valve, released, Steam, Took, me, entirely, t...  34514\n",
       "475  [A, sugar, glider, Kept, hearing, a, high, pit...  27213\n",
       "77   [In, Spanish, hats, are, called, sombrero, bec...  26416\n",
       "998                      [Fyre, Festival, VIP, suites]  24608\n",
       "78   [I, race, cars, in, an, amateur, league, There...  22677"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokenize comment (turn phrase into list of words)\n",
    "\n",
    "df['content'] = df['content'].apply(lambda comment: nltk.word_tokenize(comment))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[Valve, released, Steam, Took, me, entirely, t...</td>\n",
       "      <td>34514</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>[A, sugar, glider, Kept, hearing, a, high, pit...</td>\n",
       "      <td>27213</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>[In, Spanish, hats, are, called, sombrero, bec...</td>\n",
       "      <td>26416</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[Fyre, Festival, VIP, suites]</td>\n",
       "      <td>24608</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[I, race, cars, in, an, amateur, league, There...</td>\n",
       "      <td>22677</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  score  word_count\n",
       "96   [Valve, released, Steam, Took, me, entirely, t...  34514          12\n",
       "475  [A, sugar, glider, Kept, hearing, a, high, pit...  27213          29\n",
       "77   [In, Spanish, hats, are, called, sombrero, bec...  26416          11\n",
       "998                      [Fyre, Festival, VIP, suites]  24608           4\n",
       "78   [I, race, cars, in, an, amateur, league, There...  22677          39"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Nº words in comment\n",
    "\n",
    "df['word_count'] = df['content'].apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[Valve, released, Steam, Took, me, entirely, t...</td>\n",
       "      <td>34514</td>\n",
       "      <td>12</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>[A, sugar, glider, Kept, hearing, a, high, pit...</td>\n",
       "      <td>27213</td>\n",
       "      <td>29</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>[In, Spanish, hats, are, called, sombrero, bec...</td>\n",
       "      <td>26416</td>\n",
       "      <td>11</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[Fyre, Festival, VIP, suites]</td>\n",
       "      <td>24608</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[I, race, cars, in, an, amateur, league, There...</td>\n",
       "      <td>22677</td>\n",
       "      <td>39</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  score  word_count  \\\n",
       "96   [Valve, released, Steam, Took, me, entirely, t...  34514          12   \n",
       "475  [A, sugar, glider, Kept, hearing, a, high, pit...  27213          29   \n",
       "77   [In, Spanish, hats, are, called, sombrero, bec...  26416          11   \n",
       "998                      [Fyre, Festival, VIP, suites]  24608           4   \n",
       "78   [I, race, cars, in, an, amateur, league, There...  22677          39   \n",
       "\n",
       "     char_len  \n",
       "96         54  \n",
       "475       119  \n",
       "77         56  \n",
       "998        21  \n",
       "78        159  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Nº chars in comment\n",
    "\n",
    "df['char_len'] = df['content'].apply(lambda comment: sum(len(word) for word in comment))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_len</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[Valve, released, Steam, ., Took, me, entirely...</td>\n",
       "      <td>34514</td>\n",
       "      <td>14</td>\n",
       "      <td>56</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>[A, sugar, glider, ., Kept, hearing, a, high, ...</td>\n",
       "      <td>27213</td>\n",
       "      <td>32</td>\n",
       "      <td>122</td>\n",
       "      <td>3.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>[In, Spanish, ,, hats, are, called, ``, sombre...</td>\n",
       "      <td>26416</td>\n",
       "      <td>18</td>\n",
       "      <td>67</td>\n",
       "      <td>3.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[Fyre, Festival, VIP, suites]</td>\n",
       "      <td>24608</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>5.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[I, race, cars, in, an, amateur, league, ., Th...</td>\n",
       "      <td>22677</td>\n",
       "      <td>45</td>\n",
       "      <td>169</td>\n",
       "      <td>3.755556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  score  word_count  \\\n",
       "96   [Valve, released, Steam, ., Took, me, entirely...  34514          14   \n",
       "475  [A, sugar, glider, ., Kept, hearing, a, high, ...  27213          32   \n",
       "77   [In, Spanish, ,, hats, are, called, ``, sombre...  26416          18   \n",
       "998                      [Fyre, Festival, VIP, suites]  24608           4   \n",
       "78   [I, race, cars, in, an, amateur, league, ., Th...  22677          45   \n",
       "\n",
       "     char_len  avg_word  \n",
       "96         56  4.000000  \n",
       "475       122  3.812500  \n",
       "77         67  3.722222  \n",
       "998        21  5.250000  \n",
       "78        169  3.755556  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Character/word average\n",
    "\n",
    "def avg_word(comment):\n",
    "    return (sum(len(word) for word in comment)/len(comment))\n",
    "df['avg_word'] = df['content'].apply(avg_word)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_len</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[Valve, released, Steam, ., Took, me, entirely...</td>\n",
       "      <td>34514</td>\n",
       "      <td>14</td>\n",
       "      <td>56</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>[A, sugar, glider, ., Kept, hearing, a, high, ...</td>\n",
       "      <td>27213</td>\n",
       "      <td>32</td>\n",
       "      <td>122</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>[In, Spanish, ,, hats, are, called, ``, sombre...</td>\n",
       "      <td>26416</td>\n",
       "      <td>18</td>\n",
       "      <td>67</td>\n",
       "      <td>3.722222</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[Fyre, Festival, VIP, suites]</td>\n",
       "      <td>24608</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[I, race, cars, in, an, amateur, league, ., Th...</td>\n",
       "      <td>22677</td>\n",
       "      <td>45</td>\n",
       "      <td>169</td>\n",
       "      <td>3.755556</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  score  word_count  \\\n",
       "96   [Valve, released, Steam, ., Took, me, entirely...  34514          14   \n",
       "475  [A, sugar, glider, ., Kept, hearing, a, high, ...  27213          32   \n",
       "77   [In, Spanish, ,, hats, are, called, ``, sombre...  26416          18   \n",
       "998                      [Fyre, Festival, VIP, suites]  24608           4   \n",
       "78   [I, race, cars, in, an, amateur, league, ., Th...  22677          45   \n",
       "\n",
       "     char_len  avg_word  stopwords  \n",
       "96         56  4.000000          4  \n",
       "475       122  3.812500         12  \n",
       "77         67  3.722222          3  \n",
       "998        21  5.250000          0  \n",
       "78        169  3.755556         17  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Nº english stopwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "df['stopwords'] = df['content'].apply(lambda comment: len([word for word in comment if word in stop]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_len</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>upper_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[Valve, released, Steam, ., Took, me, entirely...</td>\n",
       "      <td>34514</td>\n",
       "      <td>14</td>\n",
       "      <td>56</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>[A, sugar, glider, ., Kept, hearing, a, high, ...</td>\n",
       "      <td>27213</td>\n",
       "      <td>32</td>\n",
       "      <td>122</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>[In, Spanish, ,, hats, are, called, ``, sombre...</td>\n",
       "      <td>26416</td>\n",
       "      <td>18</td>\n",
       "      <td>67</td>\n",
       "      <td>3.722222</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[Fyre, Festival, VIP, suites]</td>\n",
       "      <td>24608</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[I, race, cars, in, an, amateur, league, ., Th...</td>\n",
       "      <td>22677</td>\n",
       "      <td>45</td>\n",
       "      <td>169</td>\n",
       "      <td>3.755556</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  score  word_count  \\\n",
       "96   [Valve, released, Steam, ., Took, me, entirely...  34514          14   \n",
       "475  [A, sugar, glider, ., Kept, hearing, a, high, ...  27213          32   \n",
       "77   [In, Spanish, ,, hats, are, called, ``, sombre...  26416          18   \n",
       "998                      [Fyre, Festival, VIP, suites]  24608           4   \n",
       "78   [I, race, cars, in, an, amateur, league, ., Th...  22677          45   \n",
       "\n",
       "     char_len  avg_word  stopwords  upper_words  \n",
       "96         56  4.000000          4            0  \n",
       "475       122  3.812500         12            1  \n",
       "77         67  3.722222          3            0  \n",
       "998        21  5.250000          0            1  \n",
       "78        169  3.755556         17            3  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Nº of upper words\n",
    "\n",
    "df['upper_words'] = df['content'].apply(lambda comment: len([word for word in comment if word.isupper()]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(\" \".join(comment) for commet in df['content']).split(\" \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
